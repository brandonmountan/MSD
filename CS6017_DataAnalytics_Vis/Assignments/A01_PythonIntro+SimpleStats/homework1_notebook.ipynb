{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Python intro and simple statistics\n",
    "\n",
    "**Due Friday, May 24**\n",
    "\n",
    "This notebook covers Python/Numpy basics and data exploration using SLC PM2.5 air quality data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Python/Numpy\n",
    "\n",
    "### 1. Write functions to compute mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean(data):\n",
    "    \"\"\"\n",
    "    Compute the mean of a list of data\n",
    "    \n",
    "    Parameters:\n",
    "    data (list or array): Input data\n",
    "    \n",
    "    Returns:\n",
    "    float: Mean of the data\n",
    "    \"\"\"\n",
    "    return sum(data) / len(data)\n",
    "\n",
    "def compute_std(data):\n",
    "    \"\"\"\n",
    "    Compute the standard deviation of a list of data\n",
    "    \n",
    "    Parameters:\n",
    "    data (list or array): Input data\n",
    "    \n",
    "    Returns:\n",
    "    float: Standard deviation of the data\n",
    "    \"\"\"\n",
    "    mean = compute_mean(data)\n",
    "    variance = sum((x - mean) ** 2 for x in data) / (len(data) - 1)  # Sample standard deviation\n",
    "    return variance ** 0.5\n",
    "\n",
    "# Test the functions with sample data\n",
    "test_data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "print(f\"Test data: {test_data}\")\n",
    "print(f\"Custom mean: {compute_mean(test_data):.4f}\")\n",
    "print(f\"Custom std: {compute_std(test_data):.4f}\")\n",
    "print(f\"NumPy mean: {np.mean(test_data):.4f}\")\n",
    "print(f\"NumPy std: {np.std(test_data, ddof=1):.4f}\")  # ddof=1 for sample std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sample from normal distribution and verify results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for normal distribution\n",
    "true_mean = 50\n",
    "true_std = 10\n",
    "sample_size = 1000\n",
    "\n",
    "# Sample from normal distribution using scipy.stats.norm\n",
    "samples = stats.norm.rvs(loc=true_mean, scale=true_std, size=sample_size)\n",
    "\n",
    "# Compute statistics using custom functions\n",
    "custom_mean = compute_mean(samples)\n",
    "custom_std = compute_std(samples)\n",
    "\n",
    "# Compute statistics using NumPy\n",
    "numpy_mean = np.mean(samples)\n",
    "numpy_std = np.std(samples, ddof=1)\n",
    "\n",
    "# Display results\n",
    "print(f\"True parameters: mean = {true_mean}, std = {true_std}\")\n",
    "print(f\"Sample size: {sample_size}\")\n",
    "print()\n",
    "print(\"Custom functions:\")\n",
    "print(f\"  Mean: {custom_mean:.4f} (difference from true: {abs(custom_mean - true_mean):.4f})\")\n",
    "print(f\"  Std:  {custom_std:.4f} (difference from true: {abs(custom_std - true_std):.4f})\")\n",
    "print()\n",
    "print(\"NumPy functions:\")\n",
    "print(f\"  Mean: {numpy_mean:.4f} (difference from true: {abs(numpy_mean - true_mean):.4f})\")\n",
    "print(f\"  Std:  {numpy_std:.4f} (difference from true: {abs(numpy_std - true_std):.4f})\")\n",
    "print()\n",
    "print(f\"Difference between custom and NumPy mean: {abs(custom_mean - numpy_mean):.6f}\")\n",
    "print(f\"Difference between custom and NumPy std: {abs(custom_std - numpy_std):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Plot histogram of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(samples, bins=30, density=True, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Overlay theoretical normal distribution\n",
    "x = np.linspace(samples.min(), samples.max(), 100)\n",
    "theoretical_pdf = stats.norm.pdf(x, true_mean, true_std)\n",
    "plt.plot(x, theoretical_pdf, 'r-', linewidth=2, label=f'Theoretical Normal(μ={true_mean}, σ={true_std})')\n",
    "\n",
    "# Add vertical lines for means\n",
    "plt.axvline(true_mean, color='red', linestyle='--', alpha=0.8, label=f'True mean: {true_mean}')\n",
    "plt.axvline(custom_mean, color='blue', linestyle='--', alpha=0.8, label=f'Sample mean: {custom_mean:.2f}')\n",
    "\n",
    "plt.title('Histogram of Normal Distribution Samples')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Data Exploration/Analysis\n",
    "\n",
    "### Load SLC PM2.5 Data\n",
    "\n",
    "**Note:** To run this section, download a year's worth of hourly SLC PM2.5 data from https://air.utah.gov/dataarchive/archpm25.htm and place the CSV file in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PM2.5 data\n",
    "# Replace 'pm25_data.csv' with the actual filename you downloaded\n",
    "\n",
    "df = pd.read_csv('pm25_data.csv')\n",
    "print(\"Successfully loaded real PM2.5 data\")\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nColumn names:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "# Convert DateTime column to datetime if it's not already\n",
    "if 'DateTime' in df.columns:\n",
    "    df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "elif 'Date' in df.columns and 'Time' in df.columns:\n",
    "    df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n",
    "else:\n",
    "    # Try to find datetime column automatically\n",
    "    datetime_cols = [col for col in df.columns if 'date' in col.lower() or 'time' in col.lower()]\n",
    "    if datetime_cols:\n",
    "        df['DateTime'] = pd.to_datetime(df[datetime_cols[0]])\n",
    "\n",
    "# Find PM2.5 column\n",
    "pm25_cols = [col for col in df.columns if 'pm2.5' in col.lower() or 'pm25' in col.lower()]\n",
    "if pm25_cols:\n",
    "    pm25_col = pm25_cols[0]\n",
    "else:\n",
    "    pm25_col = 'PM2.5'  # Use our sample data column name\n",
    "\n",
    "print(f\"Using PM2.5 column: {pm25_col}\")\n",
    "print(f\"Date range: {df['DateTime'].min()} to {df['DateTime'].max()}\")\n",
    "print(f\"Number of records: {len(df)}\")\n",
    "\n",
    "# Select one station if multiple stations exist\n",
    "if 'Station' in df.columns:\n",
    "    stations = df['Station'].unique()\n",
    "    print(f\"\\nAvailable stations: {stations}\")\n",
    "    selected_station = stations[0]\n",
    "    df_station = df[df['Station'] == selected_station].copy()\n",
    "    print(f\"Selected station: {selected_station}\")\n",
    "    print(f\"Records for selected station: {len(df_station)}\")\n",
    "else:\n",
    "    df_station = df.copy()\n",
    "    print(\"Using all data (single station assumed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot readings over the course of a year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the full year of PM2.5 readings\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(df_station['DateTime'], df_station[pm25_col], linewidth=0.5, alpha=0.7)\n",
    "plt.title('PM2.5 Readings Over One Year', fontsize=14)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('PM2.5 (μg/m³)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"As expected, with {len(df_station)} hourly data points, this plot is quite dense.\")\n",
    "print(\"Let's explore patterns by grouping the data by month and hour.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add month and hour columns for grouping\n",
    "df_station['Month'] = df_station['DateTime'].dt.month\n",
    "df_station['Hour'] = df_station['DateTime'].dt.hour\n",
    "df_station['MonthName'] = df_station['DateTime'].dt.strftime('%B')\n",
    "\n",
    "# Calculate monthly means\n",
    "monthly_means = df_station.groupby('Month')[pm25_col].mean()\n",
    "monthly_names = df_station.groupby('Month')['MonthName'].first()\n",
    "\n",
    "# Plot monthly means as bar chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(range(1, 13), monthly_means.values, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "plt.title('Mean PM2.5 Levels by Month', fontsize=14)\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Mean PM2.5 (μg/m³)')\n",
    "plt.xticks(range(1, 13), monthly_names.values, rotation=45)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "             f'{height:.1f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Insights\n",
    "max_month = monthly_means.idxmax()\n",
    "min_month = monthly_means.idxmin()\n",
    "print(\"\\nMonthly Analysis Insights:\")\n",
    "print(f\"• Highest PM2.5 levels in {monthly_names[max_month]} ({monthly_means[max_month]:.1f} μg/m³)\")\n",
    "print(f\"• Lowest PM2.5 levels in {monthly_names[min_month]} ({monthly_means[min_month]:.1f} μg/m³)\")\n",
    "print(f\"• Seasonal variation: {monthly_means.max() - monthly_means.min():.1f} μg/m³ difference\")\n",
    "if max_month in [12, 1, 2]:\n",
    "    print(\"• Higher pollution in winter months, likely due to increased heating and atmospheric conditions\")\n",
    "if min_month in [6, 7, 8]:\n",
    "    print(\"• Lower pollution in summer months, possibly due to better atmospheric mixing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hourly Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate hourly means\n",
    "hourly_means = df_station.groupby('Hour')[pm25_col].mean()\n",
    "\n",
    "# Plot hourly means\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(hourly_means.index, hourly_means.values, marker='o', linewidth=2, markersize=6, color='darkgreen')\n",
    "plt.title('Mean PM2.5 Levels by Hour of Day', fontsize=14)\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Mean PM2.5 (μg/m³)')\n",
    "plt.xticks(range(0, 24, 2))\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels at peaks and valleys\n",
    "max_hour = hourly_means.idxmax()\n",
    "min_hour = hourly_means.idxmin()\n",
    "plt.annotate(f'Peak: {hourly_means[max_hour]:.1f}', \n",
    "             xy=(max_hour, hourly_means[max_hour]), \n",
    "             xytext=(max_hour+2, hourly_means[max_hour]+2),\n",
    "             arrowprops=dict(arrowstyle='->', color='red'))\n",
    "plt.annotate(f'Minimum: {hourly_means[min_hour]:.1f}', \n",
    "             xy=(min_hour, hourly_means[min_hour]), \n",
    "             xytext=(min_hour+2, hourly_means[min_hour]-2),\n",
    "             arrowprops=dict(arrowstyle='->', color='blue'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Insights\n",
    "print(\"\\nHourly Analysis Insights:\")\n",
    "print(f\"• Peak pollution at hour {max_hour}:00 ({hourly_means[max_hour]:.1f} μg/m³)\")\n",
    "print(f\"• Lowest pollution at hour {min_hour}:00 ({hourly_means[min_hour]:.1f} μg/m³)\")\n",
    "print(f\"• Daily variation: {hourly_means.max() - hourly_means.min():.1f} μg/m³ difference\")\n",
    "\n",
    "# Identify rush hour patterns\n",
    "morning_rush = hourly_means[6:10].mean()\n",
    "evening_rush = hourly_means[16:20].mean()\n",
    "midday = hourly_means[11:15].mean()\n",
    "night = hourly_means[22:24].mean() + hourly_means[0:6].mean()\n",
    "night = night / 2  # Average of late night and early morning\n",
    "\n",
    "print(f\"• Morning rush hours (6-9 AM): {morning_rush:.1f} μg/m³\")\n",
    "print(f\"• Evening rush hours (4-7 PM): {evening_rush:.1f} μg/m³\")\n",
    "print(f\"• Midday (11 AM-2 PM): {midday:.1f} μg/m³\")\n",
    "print(f\"• Night time (10 PM-5 AM): {night:.1f} μg/m³\")\n",
    "\n",
    "if morning_rush > midday or evening_rush > midday:\n",
    "    print(\"• Higher pollution during rush hours suggests traffic-related emissions\")\n",
    "if night < midday:\n",
    "    print(\"• Lower nighttime pollution suggests reduced human activity and better atmospheric dispersion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box and Whisker Plots for More Complete Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly box plot\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "df_station.boxplot(column=pm25_col, by='Month', ax=plt.gca())\n",
    "plt.title('PM2.5 Distribution by Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('PM2.5 (μg/m³)')\n",
    "plt.xticks(range(1, 13), [monthly_names[i] for i in range(1, 13)], rotation=45)\n",
    "plt.suptitle('')  # Remove automatic title\n",
    "\n",
    "# Hourly box plot\n",
    "plt.subplot(1, 2, 2)\n",
    "df_station.boxplot(column=pm25_col, by='Hour', ax=plt.gca())\n",
    "plt.title('PM2.5 Distribution by Hour of Day')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('PM2.5 (μg/m³)')\n",
    "plt.xticks(range(1, 25, 2), range(0, 24, 2))\n",
    "plt.suptitle('')  # Remove automatic title\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More detailed box plot analysis\n",
    "# Calculate quartiles and outliers for monthly data\n",
    "monthly_stats = df_station.groupby('Month')[pm25_col].describe()\n",
    "hourly_stats = df_station.groupby('Hour')[pm25_col].describe()\n",
    "\n",
    "print(\"Box Plot Analysis Insights:\")\n",
    "print(\"\\nMonthly Patterns:\")\n",
    "highest_variability_month = (monthly_stats['75%'] - monthly_stats['25%']).idxmax()\n",
    "lowest_variability_month = (monthly_stats['75%'] - monthly_stats['25%']).idxmin()\n",
    "print(f\"• Highest variability in {monthly_names[highest_variability_month]} (IQR: {monthly_stats.loc[highest_variability_month, '75%'] - monthly_stats.loc[highest_variability_month, '25%']:.1f})\")\n",
    "print(f\"• Lowest variability in {monthly_names[lowest_variability_month]} (IQR: {monthly_stats.loc[lowest_variability_month, '75%'] - monthly_stats.loc[lowest_variability_month, '25%']:.1f})\")\n",
    "\n",
    "# Check for extreme outliers\n",
    "outlier_months = []\n",
    "for month in range(1, 13):\n",
    "    month_data = df_station[df_station['Month'] == month][pm25_col]\n",
    "    q75 = month_data.quantile(0.75)\n",
    "    q25 = month_data.quantile(0.25)\n",
    "    iqr = q75 - q25\n",
    "    outlier_threshold = q75 + 1.5 * iqr\n",
    "    outliers = (month_data > outlier_threshold).sum()\n",
    "    if outliers > len(month_data) * 0.05:  # More than 5% outliers\n",
    "        outlier_months.append((monthly_names[month], outliers))\n",
    "\n",
    "if outlier_months:\n",
    "    print(f\"\\nMonths with frequent high pollution episodes:\")\n",
    "    for month, count in outlier_months:\n",
    "        print(f\"• {month}: {count} extreme readings\")\n",
    "\n",
    "print(\"\\nHourly Patterns:\")\n",
    "highest_variability_hour = (hourly_stats['75%'] - hourly_stats['25%']).idxmax()\n",
    "lowest_variability_hour = (hourly_stats['75%'] - hourly_stats['25%']).idxmin()\n",
    "print(f\"• Highest variability at {highest_variability_hour}:00 (IQR: {hourly_stats.loc[highest_variability_hour, '75%'] - hourly_stats.loc[highest_variability_hour, '25%']:.1f})\")\n",
    "print(f\"• Most consistent levels at {lowest_variability_hour}:00 (IQR: {hourly_stats.loc[lowest_variability_hour, '75%'] - hourly_stats.loc[lowest_variability_hour, '25%']:.1f})\")\n",
    "\n",
    "print(\"\\nAdditional Insights from Box Plots:\")\n",
    "print(\"• Box plots reveal the full distribution shape, showing skewness and outliers\")\n",
    "print(\"• Outliers indicate pollution episodes that may warrant further investigation\")\n",
    "print(\"• The interquartile range shows the typical day-to-day variation\")\n",
    "print(\"• Comparing medians vs means can reveal whether data is skewed by extreme events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This homework demonstrates:\n",
    "\n",
    "### Python/NumPy Skills:\n",
    "- Implementation of basic statistical functions (mean, standard deviation)\n",
    "- Working with scipy.stats for probability distributions\n",
    "- Data visualization with matplotlib\n",
    "- Verification that sample statistics converge to theoretical values\n",
    "\n",
    "### Data Analysis Skills:\n",
    "- Loading and preprocessing real-world environmental data\n",
    "- Time series analysis and temporal grouping\n",
    "- Statistical visualization techniques (histograms, bar charts, line plots, box plots)\n",
    "- Pattern recognition in environmental data (seasonal and diurnal cycles)\n",
    "- Understanding the value of different visualization approaches for gaining insights\n",
    "\n",
    "The analysis reveals typical air quality patterns including seasonal variations (higher in winter) and daily cycles (peaks during rush hours), providing valuable insights into pollution sources and atmospheric processes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
